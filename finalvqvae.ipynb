{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58cfdc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d062f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pkl files/chunks.pkl\", \"rb\") as f:\n",
    "    chunks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d544021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing models\n",
    "from vqmodel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af4d3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to tensor transition\n",
    "images = []\n",
    "\n",
    "for df in chunks:\n",
    "    # df['ch'] is a Series of 80 columns; each item is a list of 200 values\n",
    "    # Create a (200, 80) NumPy array (transpose is needed)\n",
    "    matrix = np.stack(df['PWR_ch1'].to_list(), axis=1)  # shape: (200, 80)\n",
    "    images.append(matrix)\n",
    "\n",
    "# Convert the whole thing to numpy because making tensors from a list of arrays\n",
    "# is extremely slow\n",
    "images_array = np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8e389b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensor and add batch + channel dimensions\n",
    "data_tensor = torch.tensor(images_array, dtype=torch.float32)  # (B, 200, 80)\n",
    "data_tensor = data_tensor.unsqueeze(1)  # (B, 1, 200, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f64eb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 200, 80])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = ChunkImageDataset(chunks)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "model = VQVAE(in_channels=1)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch.shape)  # (8, 1, 200, 80)\n",
    "    outputs = model(batch)\n",
    "    break  # for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96193a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. First split: 80% train, 20% temp\n",
    "train_chunks, temp_chunks = train_test_split(\n",
    "    chunks, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "498f88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split temp into 10% val, 10% test\n",
    "val_chunks, test_chunks = train_test_split(\n",
    "    temp_chunks, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00fa57df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2478\n",
      "Validation: 310\n",
      "Test: 310\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check counts\n",
    "print(f\"Train: {len(train_chunks)}\")\n",
    "print(f\"Validation: {len(val_chunks)}\")\n",
    "print(f\"Test: {len(test_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e4dacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Wrap into datasets\n",
    "train_dataset = ChunkImageDataset(train_chunks)\n",
    "val_dataset = ChunkImageDataset(val_chunks)\n",
    "test_dataset = ChunkImageDataset(test_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d092207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be8bc8",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e61cba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vqvae(model, train_loader, val_loader, optimizer, device=\"cuda\", epochs=500):\n",
    "    model.to(device)\n",
    "\n",
    "    # Initialize plot variables\n",
    "    train_losses, val_losses = [], []\n",
    "    recon_losses, vq_losses = [], []\n",
    "    code_usages, zq_stds = [], []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss, recon_total, vq_total = 0, 0, 0\n",
    "        code_indices_set = set()\n",
    "        zq_std_list = []\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch)\n",
    "            out[\"total_loss\"].backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += out[\"total_loss\"].item() * batch.size(0)\n",
    "            recon_total += out[\"recon_loss\"].item() * batch.size(0)\n",
    "            vq_total += out[\"vq_loss\"].item() * batch.size(0)\n",
    "            code_indices_set.update(out[\"indices\"].detach().cpu().numpy().tolist())\n",
    "            zq_std_list.append(out[\"z_q\"].std().item())\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch)\n",
    "                val_loss += F.mse_loss(out[\"recon_x\"], batch).item() * batch.size(0)\n",
    "\n",
    "        train_losses.append(total_loss / len(train_loader.dataset))\n",
    "        val_losses.append(val_loss / len(val_loader.dataset))\n",
    "        recon_losses.append(recon_total / len(train_loader.dataset))\n",
    "        vq_losses.append(vq_total / len(train_loader.dataset))\n",
    "        code_usages.append(len(code_indices_set))\n",
    "        zq_stds.append(np.mean(zq_std_list))\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Train Loss: {train_losses[-1]:.4f} | \"\n",
    "              f\"Val Loss: {val_losses[-1]:.4f} | \"\n",
    "              f\"Codes Used: {code_usages[-1]}\")\n",
    "        print(f\"z_q mean: {out['z_q'].mean().item():.6f} | std: {zq_stds[-1]:.6f}\")\n",
    "\n",
    "    # Plotting\n",
    "    epochs_range = range(1, epochs + 1)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs_range, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs_range, val_losses, label='Val Loss')\n",
    "    plt.title(\"Total Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs_range, recon_losses, label='Reconstruction Loss')\n",
    "    plt.title(\"Reconstruction Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs_range, vq_losses, label='VQ Loss')\n",
    "    plt.title(\"VQ Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(epochs_range, code_usages, label='Unique Codes Used')\n",
    "    plt.title(\"Codebook Usage\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d31457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 1.4301 | Val Loss: 0.7682 | Codes Used: 60\n",
      "z_q mean: 0.065326 | std: 0.502104\n",
      "[Epoch 2] Train Loss: 1.8675 | Val Loss: 0.7133 | Codes Used: 69\n",
      "z_q mean: 0.051838 | std: 0.519405\n",
      "[Epoch 3] Train Loss: 1.6549 | Val Loss: 0.6937 | Codes Used: 73\n",
      "z_q mean: 0.046422 | std: 0.531193\n",
      "[Epoch 4] Train Loss: 1.6242 | Val Loss: 0.6738 | Codes Used: 59\n",
      "z_q mean: 0.030272 | std: 0.544589\n",
      "[Epoch 5] Train Loss: 1.5432 | Val Loss: 0.6541 | Codes Used: 59\n",
      "z_q mean: 0.017414 | std: 0.548272\n"
     ]
    }
   ],
   "source": [
    "model = VQVAE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_vqvae(model, train_loader, val_loader, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b45aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model pt files/vqvae_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
